{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Light Gradient Boost Machine for Prediction of Sale Price of Bulldozers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use the Kaggle Dataset [Blue Book for Bulldozers](https://www.kaggle.com/competitions/bluebook-for-bulldozers/) to train a machine learning model that predicts the sale price of heavy machinery at auction based on factors like its configuration, usage, etc. \n",
    "\n",
    "Primary focuses will be on cleaning the data in an attempt to feed the most relevant pieces of information to the ML model, and then using LGBM for the actual model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Please install the lightgbm library if not already installed by uncommenting the following line: \n",
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset obtained from [Kaggle](https://www.kaggle.com/competitions/bluebook-for-bulldozers/overview). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train.csv\", low_memory=False, parse_dates=[\"saledate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step SaleDate column is split into 'Year' and 'Month'. These features can be helpful in making predictions about the sale price. \n",
    "\n",
    "'Year' is helpful as prices of used vehicles tend to lower over years, but newer vehicles become more expensive due to inflation. The hope is that the model can capture trends from this information.  \n",
    "\n",
    "'Month' is potentially useful, as prices can wary according to season, especially in parts where construction may be unfeasible over the winters etc. and machines are going to be unused commodities for some months.  \n",
    "\n",
    "Experimentation was also done with making columns for the Day, Day of the week, and Day of the year, but these lead to poorer performance of the model, most likely as the model would find it difficult to extract meaningful information from these and may be slightly overfitting to them. So it was decided to not include those. \n",
    "\n",
    "The original 'saledate' column is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"saleYear\"] = df.saledate.dt.year\n",
    "df[\"saleMonth\"] = df.saledate.dt.month\n",
    "# df[\"saleDay\"] = df.saledate.dt.day\n",
    "# df[\"saleDayOfWeek\"] = df.saledate.dt.dayofweek\n",
    "# df[\"saleDayOfYear\"] = df.saledate.dt.dayofyear\n",
    "df.drop(\"saledate\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There currently are a lot of null values in the dataset. Some of these columns already have \"None or Unspecified\" entries. This effectively means that \"None of Unspecified\" is a valid value. \n",
    "\n",
    "So, we find any columns that contain such \"None or Unspecified\" values, and just replace the actual null values with \"None or Unspecified\" to complete these columns. This ensures that the rest of the information in these columns can be used and they do not have to be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if (df[column] == 'None or Unspecified').any():\n",
    "        df[column] = df[column].fillna('None or Unspecified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There still are many columns that have many missing values. Generally, it is not great to impute values in columns that have majority missing values, as whatever statistic we impute with (mean, median, etc.) could be misleading when the statistic is being calculate with such little information. \n",
    "\n",
    "Therefore, columns with more than 75% missing values were dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to be dropped: ['UsageBand', 'fiModelSeries', 'fiModelDescriptor', 'Stick', 'Engine_Horsepower', 'Track_Type', 'Grouser_Type', 'Differential_Type', 'Steering_Controls']\n"
     ]
    }
   ],
   "source": [
    "percentage_missing = df.isna().sum() / len(df) * 100\n",
    "columns_to_drop = percentage_missing[percentage_missing > 75].index\n",
    "\n",
    "print(\"Columns to be dropped:\", list(columns_to_drop))\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was understood in-depth and analyzed manually by using the \"Data Dictionary.xlsx\" provided by Kaggle. This document contains brief descriptions of what each feature in the dataset means (where each feature is some characteristic of the machine being sold). \n",
    "\n",
    "Many features that could be either useless or redundant (as in, features that were one-to-one related to other features) were shortlisted: \n",
    "- SalesID\n",
    "- MachineID\n",
    "- state\n",
    "- fiModelDesc\n",
    "- fiBaseModel\n",
    "- fiSecondaryDesc\n",
    "- fiProductClassDesc\n",
    "- datasource\n",
    "- auctioneerID\n",
    "- ProductGroupDesc\n",
    "\n",
    "Experimentation was done with dropping some of them.  \n",
    "\n",
    "Somewhat counter-intuitively, dropping most of these columns made the model's performance ever so slightly worse on the RMSLE. So, most of them were kept and the model learn was given a freehand to learn by itself. Only a few columns were dropped where an actual improvement was observed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop2 = ['datasource', 'auctioneerID', 'ProductGroupDesc']\n",
    "\n",
    "df = df.drop(columns=columns_to_drop2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step values that are still missing are being catered.\n",
    "1. Numeric columns with missing values are imputed with the median. This is because the median is less sensitive to outliers compared to mean. \n",
    "2. Categorical columns are imputed with the most frequent value in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "df[df.select_dtypes(include=['float64']).columns] = numeric_imputer.fit_transform(df.select_dtypes(include=['float64']))\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[df.select_dtypes(include=['object']).columns] = categorical_imputer.fit_transform(df.select_dtypes(include=['object']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enconding of Categorical Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all the data for our LGBM model has to be in numerical form, categorical columns in the dataset were selected and coverted into numerical form using label encoding.\n",
    "\n",
    "Label encoding transforms categorical data into a simple numerical format that is efficient in terms of memory and computation as our dataset is very large (around 401k rows). Thus, it was chosen over one-hot encoding (which would vastly increase the size of dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = LabelEncoder().fit_transform(df[column])\n",
    "\n",
    "# df = pd.get_dummies(df, columns=df.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into: \n",
    "- X -> Features\n",
    "- y -> labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('SalePrice', axis=1)\n",
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320900, 41)\n",
      "(320900,)\n",
      "(80225, 41)\n",
      "(80225,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into training and validation sets\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingg LGBM Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lgb.Dataset function converts this data into a format that is internally optimized for speed and memory usage by LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step two things are done:\n",
    "\n",
    "1. The parameters of the LGBM are defined. These include: \n",
    "- the type of model ('gbdt' for gradient boosted decision trees)\n",
    "- the objective (regression)\n",
    "- Metric:{'l2', 'l1'} (to use both L1 and L2 regression, as L2 is more sensitive to outliers and vice versa)\n",
    "- num_leaves (a key paramter which specifies the maximum number of leaves in one tree, controlling the complexity of the model) \n",
    "- learning rate \n",
    "\n",
    "2. LGBM model is trainined on X_train. 'num_boost_round' indicates the number of boosting iterations. Early_stopping_rounds is used to stop training if the validation score does not improve for 5 consecutive rounds, which helps in preventing overfitting.\n",
    "\n",
    "Note: Increasing the num_boost_round decreased the rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[90]\tvalid_0's l1: 6739.08\tvalid_0's l2: 9.97596e+07\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=90,\n",
    "                valid_sets=lgb_eval,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=5)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Prediction and Calculating RMSLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model is now used to predict the sale price on the validation set. \n",
    "\n",
    "RMSLE (Root Mean Squared Logarithmic Error) is used to evaluate model performance. The RMSLE is a measure of the ratio between the actual and predicted values. The logarithmic part of the equation helps evaluate performance well in cases where the target variable has a wide range of values. Our target variable here is the price of the tractor, and it does indeed have a very wide range or possible values. Also, RMSLE was the metric used to evaluate the performance of the models in the original Kaggle competition for this dataset. \n",
    "\n",
    "A smaller RMSLE value means better performance, with 0 being the ideal score indicating perfect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE on validation set: 0.31593054635125856\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rmsle = np.sqrt(mean_squared_error(np.log1p(y_val), np.log1p(y_pred)))\n",
    "print(\"RMSLE on validation set:\", rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSLE value of ~0.3159 obtained is a fairly good value, amongst the top 100 in the [Kaggle competition leaderboards](https://www.kaggle.com/competitions/bluebook-for-bulldozers/leaderboard). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
